{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f1be328",
   "metadata": {},
   "source": [
    "# Tutorial 3: Demystifying our data transformations -- Mastering the MasterTransformation\n",
    "\n",
    "The goal of this tutorial is to understand the MasterTransformation class that handles the transformation of data samples before they can be passed to the model for training. The tutorial also includes a visualization of the most important transforms the so-called basis transforms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe5acbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary packages\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import rich\n",
    "import torch\n",
    "from hydra import compose, initialize\n",
    "from hydra.utils import instantiate\n",
    "\n",
    "# this makes sure that code changes are reflected without restarting the notebook\n",
    "# this can be helpful if you want to play around with the code in the repo\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# omegaconf is used for configuration management\n",
    "# omegaconf custom resolvers are small functions used in the config files like \"get_len\" to get lengths of lists\n",
    "from mldft.utils import omegaconf_resolvers  # this registers omegaconf custom resolvers\n",
    "from mldft.utils.log_utils.config_in_tensorboard import dict_to_tree\n",
    "from mldft.utils.molecules import build_molecule_ofdata\n",
    "\n",
    "# download a small dataset from huggingface that contains QM9 and QMugs data (possibly already downloaded)\n",
    "# and change the DFT_DATA environment variable to the directory where the data is stored\n",
    "\n",
    "# https://huggingface.co/docs/datasets/cache#cache-directory\n",
    "# The default cache directory is `~/.cache/huggingface/datasets`\n",
    "# You can change it by setting this variable to any path you like\n",
    "CACHE_DIR = None  # e.g. change it to \"./hf_cache\"\n",
    "\n",
    "# clone the full repo\n",
    "# https://huggingface.co/sciai-lab/structures25/tree/main\n",
    "os.environ[\n",
    "    \"HF_HUB_DISABLE_PROGRESS_BARS\"\n",
    "] = \"1\"  # to avoid problems with the progress bar in some environments\n",
    "from huggingface_hub import snapshot_download\n",
    "\n",
    "data_path = snapshot_download(\n",
    "    repo_id=\"sciai-lab/minimal_data_QM9_QMugs\", cache_dir=CACHE_DIR, repo_type=\"dataset\"\n",
    ")\n",
    "\n",
    "dft_data = os.environ.get(\"DFT_DATA\", None)\n",
    "os.environ[\"DFT_DATA\"] = data_path\n",
    "print(\n",
    "    f\"Environment variable DFT_DATA has been changed from {dft_data} to {os.environ['DFT_DATA']}.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a6c66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, we load our large config, instantiate the datamodule and obtain a single sample\n",
    "with initialize(version_base=None, config_path=\"../../configs/ml\"):\n",
    "    config = compose(\n",
    "        config_name=\"train.yaml\",\n",
    "        overrides=[],\n",
    "    )\n",
    "\n",
    "# remove the hydra specific stuff that only works in @hydra.main decorated functions\n",
    "config.paths.output_dir = \"example_path\"\n",
    "\n",
    "datamodule = instantiate(config.data.datamodule)\n",
    "datamodule.setup(stage=\"fit\")\n",
    "sample = datamodule.train_set[0]\n",
    "\n",
    "# need basis info to build a pySCF molecule object\n",
    "# see below for more details on basis_info\n",
    "basis_info = instantiate(config.data.basis_info)\n",
    "\n",
    "# build a pySCF molecule object from the OFData sample\n",
    "mol = build_molecule_ofdata(sample, basis=basis_info.basis_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b324b5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one important but (slightly) tricky topic are the transforms that are applied\n",
    "#  to a data sample when loaded from the dataset\n",
    "rich.print(dict_to_tree(config.data.transforms, guide_style=\"dim\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b97efb0",
   "metadata": {},
   "source": [
    "## 1 The MasterTransformation class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf612d4",
   "metadata": {},
   "source": [
    "Some of our data transformations are quite expensive and should therefore not be performed on the fly during training.\n",
    "As a solution, we have precomputed several different transformed versions of our datasets and saved them to the file servers (we call this cached data).\n",
    "In this tutorial, two transforms have been applied previously to the data and are loaded as \"cached\":\n",
    "* the transformation into local frames (local reference frames at every atom)\n",
    "* and the global symmetric natural reparametrization (natrep),\n",
    "that is, an orthonormalization of the basis functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d9259ba",
   "metadata": {},
   "source": [
    "### Cached data, basis transforms, pre- and post transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac38f8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all transforms are combined into one class called the MasterTransformation\n",
    "from mldft.ml.data.components.basis_transforms import MasterTransformation\n",
    "\n",
    "datamodule.transforms.__dict__\n",
    "print(\"Name of (cached) transforms:\", datamodule.transforms.name)\n",
    "print(\"Whether to use cached data:\", datamodule.transforms.use_cached_data, \"\\n\")\n",
    "print(\"cached_basis_transforms:\", datamodule.transforms.cached_basis_transforms, \"\\n\")\n",
    "# these transforms must therefore not be applied on the fly during training if cached data is used\n",
    "# however if use_cached_data=FALSE, these transforms are actually still applied on the fly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c03922",
   "metadata": {},
   "source": [
    "Global symmetric natrep is the reason that the basis function integrals are no longer zero for a majority of the basis functions (l>0 prior to natrep, cf. [Tutorial 1](./tutorial_1_datamodule.ipynb)).\n",
    "In fact, natrep performs a change of basis to a new set of basis functions that are **orthonormal** on a global level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0e5843",
   "metadata": {},
   "outputs": [],
   "source": [
    "# basis function integrals are no longer zero:\n",
    "# side note: just ignore the word \"dual\" in the \"dual_basis_integrals\" attribute name\n",
    "print(\"Basis function integrals after natrep (first 10):\", sample.dual_basis_integrals[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed472e9b",
   "metadata": {},
   "source": [
    "#### Global symmetric natrep\n",
    "By diagonalizing the overlap matrix $O_{\\mu\\nu}$ of the basis functions $\\omega_\\mu$,\n",
    "$$\n",
    "O_{\\mu\\nu} = \\int \\mathrm d^3r \\ \\omega_\\mu \\omega_\\nu \n",
    "$$,\n",
    "we find a change of basis that can be used to make all basis functions mutually orthogonal. Furthermore, we can normalize the resulting basis functions so that the overlap matrix in the transformed basis becomes the identity matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "381e04cb",
   "metadata": {},
   "source": [
    "All other transforms are applied on the fly during training\n",
    "but there are several different types of such transforms:\n",
    "\n",
    "First, the **pre_transforms** are directly applied to the OFData sample when it is loaded from the disk.\n",
    "All molecules (transformed or not) are saved as individual zarr files on the disk.\n",
    "\n",
    "In the default case the pre_transforms are\n",
    "* ToTorch: to convert numpy arrays to torch tensors\n",
    "* ProjectGradient: to project the gradient label orthogonally to the direction in which the number of electrons changes\n",
    "(this is important since we want to keep the number of electrons constant during density optimization)\n",
    "* AddFullEdgeIndex: to add a list of edges of a fully connected graph to the sample data\n",
    "(used for message passing neural networks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4566189e",
   "metadata": {},
   "source": [
    "#### Gradient projection\n",
    "The gradient projection ensures that a step in the direction of the gradient will not change the number of electrons.\n",
    "\n",
    "Let $\\mathrm w_\\mu$ be the integral of the basis functions $\\omega(\\vec r)$:\n",
    "$$\n",
    "\\mathrm w_\\mu = \\int \\mathrm d^3 \\ \\vec r \\omega_\\mu(\\vec r)\n",
    "$$ \n",
    "The number of electrons for a given density is then:\n",
    "$$\n",
    "N_e = \\int \\mathrm d^3 \\ \\vec r \\sum_\\mu p_\\mu \\omega_\\mu(\\vec r) = \\sum_\\mu p_\\mu \\mathrm w_\\mu = \\mathbf p^T \\mathbf w\n",
    "$$.\n",
    "If we collect all $\\mathrm w_\\mu$ in a vector $\\mathbf w$, then the projection operator that acts on the gradients is given by\n",
    "$$\n",
    "\\Pi = I - \\frac{\\mathbf w \\mathbf w^T}{\\mathbf w^T\\mathbf w}\n",
    "$$. One can easily check that indeed $\\Pi \\Pi = \\Pi$. If we now consider an arbitrary change to our density $p \\to p' = p + \\Delta p$ the number of electrons of the density will change. But for $p \\to p' = p + \\Pi \\Delta p$ is stays constant:\n",
    "$$\n",
    "N_e' = (\\mathbf p + \\Pi \\Delta \\mathbf p)^T \\mathbf w = (\\mathbf p^T + \\Delta \\mathbf p^T \\Pi^T)  \\mathbf w = N_e + \\Delta \\mathbf p^T \\Big(I - \\frac{\\mathbf w \\mathbf w^T}{\\mathbf w^T\\mathbf w} \\Big) \\mathbf w = N_e + \\Delta \\mathbf p^T \\Big(\\mathbf w - \\mathbf w \\frac{\\mathbf w^T\\mathbf w}{\\mathbf w^T\\mathbf w}\\Big) = N_e\n",
    "$$.\n",
    "Indeed, $\\Pi$ is a projection operator that when applied to the gradient step ($\\Delta \\mathbf p = \\text{learning rate} \\times \\nabla_p E$) preserves the number of electrons $N_e$ of the corresponding electron density."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd598b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"pre_transforms:\", datamodule.transforms.pre_transforms)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23cd3b4d",
   "metadata": {},
   "source": [
    "Second, **additional_pre_transforms**: In contrast to pre_transforms,\n",
    "additional_pre_transforms are only used if NOT cached data is used\n",
    "therefore, in our case even though it is specified in the config the\n",
    "AddOverlapMatrix transform is not applied.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffdc8e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"additional_pre_transforms:\", datamodule.transforms.additional_pre_transforms)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9417ce4",
   "metadata": {},
   "source": [
    "Third, the **basis_transforms** are always applied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ace12c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# since we use cached data, we do not apply any basis transforms on the fly\n",
    "print(\"basis_transforms:\", datamodule.transforms.basis_transforms, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c85cb7ae",
   "metadata": {},
   "source": [
    "Fourth, the **post_transforms**: These are also always applied\n",
    "and typically prepare the data for the model,\n",
    "e.g. one can change the dtype here between float32 and float64.\n",
    "In the default case, we use ToTorch to make sure that all attributes in OFData are converted to torch tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a85639e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"post_transforms:\", datamodule.transforms.post_transforms)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdbf0e8f",
   "metadata": {},
   "source": [
    "**The reason for our complicated transform structure is the following:**  \n",
    "Basis transforms, such as the local frames transforms or the natrep transformation, affect the basis functions (see below). Therefore, for consistency, basis transforms transform *all* fields in the sample according to their geometric representation. Thus, the pre_transforms are important to potentially add attributes to the data samples which should then be affected by the basis transforms, e.g. the AddOverlapMatrix transform."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b779ee4e",
   "metadata": {},
   "source": [
    "Next, let us manually change the `use_cached_data` to False such that\n",
    "AddOverlapMatrix transform will actually be applied.\n",
    "In that case, the data will be loaded as untransformed data\n",
    "and then the LocalFrames and SymmetricGlobalNatrep basis transforms will be applied on the fly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604c7f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# let us initialize a second datamodule but with use_cached_data=False\n",
    "with initialize(version_base=None, config_path=\"../../configs/ml\"):\n",
    "    config_no_cache = compose(\n",
    "        config_name=\"train.yaml\",\n",
    "        overrides=[\n",
    "            # we need one simple override here but otherwise we just use the default setting (see tutorial 4 for more information)\n",
    "            \"data.transforms.use_cached_data=False\",  # override to not use cached data\n",
    "        ],\n",
    "    )\n",
    "\n",
    "# remove the hydra specific stuff that only works in @hydra.main decorated functions\n",
    "config_no_cache.paths.output_dir = \"example_path\"\n",
    "\n",
    "datamodule_no_cache = instantiate(config_no_cache.data.datamodule)\n",
    "datamodule_no_cache.setup(stage=\"fit\")\n",
    "\n",
    "t0 = time.time()\n",
    "sample_cache = datamodule.train_set[0]\n",
    "print(\n",
    "    f\"Sample has overlap_matrix: {hasattr(sample_cache, 'overlap_matrix')}, since pre_transforms are not used.\"\n",
    ")\n",
    "print(f\"Loading sample with cached transforms took: {time.time()-t0:.2f} seconds\")\n",
    "t0 = time.time()\n",
    "sample_no_cache = datamodule_no_cache.train_set[0]\n",
    "print(\n",
    "    f\"Sample has overlap_matrix: {hasattr(sample_no_cache, 'overlap_matrix')}, since pre_transforms are used.\"\n",
    ")\n",
    "print(f\"Loading sample without cached transforms took: {time.time()-t0:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5072ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can confirm that after symmetric global natrep,\n",
    "# the overlap matrix of the basis functions is indeed close to the identity matrix:\n",
    "print(\n",
    "    \"Overlap matrix close to identity\",\n",
    "    torch.allclose(sample_no_cache.overlap_matrix, torch.eye(sample_no_cache.coeffs.shape[0])),\n",
    ")\n",
    "\n",
    "# let's confirm that otherwise the two samples are identical\n",
    "for key in [\"pos\", \"coeffs\", \"ground_state_coeffs\", \"dual_basis_integrals\"]:\n",
    "    print(\n",
    "        f\"Checking that {key} are close:\", torch.allclose(sample_cache[key], sample_no_cache[key])\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f771e790",
   "metadata": {},
   "source": [
    "## 2 Visualization of local frames transformation\n",
    "In our project (when using the Graphformer architecture as in STRUCTURES25), we use local frames to canonicalize the geometric input data to achieve rotational equivariance.\n",
    "\n",
    "Therefore, let us visualize the local frames (computed base on nearest neighbor positions):\n",
    "Note that the x-axis (the green arrow) of the local frames is not visible as it always points towards the nearest neighbor atom and is therefore \"swallowed\" by the bond between these two atoms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647e5340",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# keep only the program name so downstream parsers don't see Jupyter's -f=...\n",
    "sys.argv = sys.argv[:1]\n",
    "\n",
    "import pyvista\n",
    "\n",
    "# let use explictily calculate local frames for the given sample:\n",
    "from mldft.ml.models.components.local_frames_module import (\n",
    "    LocalFramesTransformMatrixDense,\n",
    ")\n",
    "from mldft.utils.visualize_3d import (\n",
    "    get_local_frames_mesh_dict,\n",
    "    get_sticks_mesh_dict,\n",
    "    visualize_orbital,\n",
    ")\n",
    "\n",
    "# predict the local frames from the atomic positions and atom types:\n",
    "local_frames_module = LocalFramesTransformMatrixDense()\n",
    "transformation_matrix, lframes = local_frames_module.sample_forward(sample, return_lframes=True)\n",
    "\n",
    "local_frames_mesh = get_local_frames_mesh_dict(\n",
    "    origins=sample.pos,\n",
    "    bases=lframes,\n",
    "    scale=2,\n",
    "    # axes_radius_scale=0.06\n",
    ")\n",
    "\n",
    "# this gives a ball and stick model of the molecule\n",
    "molecule_mesh = get_sticks_mesh_dict(mol)\n",
    "molecule_mesh[\"opacity\"] = 1\n",
    "\n",
    "# plot the molecule and the global frame using pyvista:\n",
    "pyvista.set_jupyter_backend(\"html\")\n",
    "pl = pyvista.Plotter(off_screen=True, notebook=True, image_scale=1)\n",
    "pl.add_mesh(**local_frames_mesh)\n",
    "pl.add_mesh(**molecule_mesh)\n",
    "pl.enable_shadows()\n",
    "pl.reset_camera(\n",
    "    bounds=0.9 * np.stack([mol.atom_coords().min(0), mol.atom_coords().max(0)], axis=1).flatten()\n",
    ")\n",
    "\n",
    "print(\"3d visualization of local coordinate frames at every atom:\")\n",
    "img = pl.show(screenshot=True, window_size=(800, 400))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55708b8e",
   "metadata": {},
   "source": [
    "Let us illustrate the effect of the local frames transformation at a single basis function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a36e39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let us visualize a single basis function:\n",
    "basis_function_idx = 370\n",
    "node_idx = sample.coeff_ind_to_node_ind[basis_function_idx]\n",
    "coeffs = np.zeros(sample.coeffs.shape)\n",
    "coeffs[basis_function_idx] = 1.0  # set one coefficient to one, all others to zero\n",
    "\n",
    "# this can be used to visualize local frames\n",
    "# (in this case the global coordinate frame at the position at the atom)\n",
    "global_frame_mesh = get_local_frames_mesh_dict(\n",
    "    origins=sample.pos[node_idx].view(1, 3),\n",
    "    # origins=torch.zeros(1, 3),\n",
    "    bases=torch.eye(3)[None],\n",
    "    scale=2,\n",
    ")\n",
    "\n",
    "pl = pyvista.Plotter(off_screen=True, notebook=True, image_scale=1)\n",
    "pl = visualize_orbital(\n",
    "    mol=mol,\n",
    "    coeff=coeffs,\n",
    "    plotter=pl,\n",
    "    mode=\"isosurface\",\n",
    "    resolution=0.15,\n",
    "    isosurface_quantile=0.6,\n",
    ")\n",
    "\n",
    "pl.add_mesh(**global_frame_mesh)\n",
    "print(\"P-Orbital like basis function without transforms (and global frame):\")\n",
    "img = pl.show(screenshot=True, window_size=(800, 400))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a02adc07",
   "metadata": {},
   "source": [
    "#### How to visualize transformed basis functions (some cool theory)\n",
    "\n",
    "The basis functions are taken from the BasisInfo object (see above where it is initialized, and [Tutorial1](./tutorial_1_datamodule.ipynb) for more details). Short recap: The basis functions $\\omega_\\mu(\\vec r)$ are used to represent the electron density $\\rho(\\vec r)$ via linear combination:\n",
    "$$\n",
    "\\rho(\\vec r) = \\sum_\\mu p_\\mu \\omega_\\mu(\\vec r) = \\mathbf p^T \\boldsymbol \\omega(\\vec r),\n",
    "$$\n",
    "where we have grouped the coefficients $p_\\mu$ and basis functions $\\omega_\\mu$ in $d$-dimensional vectors, i.e. $\\mathbf p, \\boldsymbol \\omega(\\vec r) \\in \\mathbb R^d$.\n",
    "\n",
    "A basis transformation changes the basis function $\\omega_\\mu$ into new $\\omega'_\\mu$ that are a linear combination of the $\\omega_\\mu$. Similarly, the coefficients are transformed into $p'_\\mu$ that are a linear combination of the $p_\\mu$. Let $A \\in \\mathrm{GL}(d)$ be a real $d \\times d$ basis transformation matrix. Under this transformation, we *demand* that the coefficients transform like vectors, i.e. $p'_\\mu = \\sum_\\nu A_{\\mu \\nu}  p_\\nu$ or in short $\\mathbf p' = A \\mathbf p$. \n",
    "\n",
    "Now, we ask the following question: How must the transformed $\\omega'_\\mu$ look like so that the density function stays the same, i.e. $\\rho'(\\vec r) =  \\mathbf p'^T \\boldsymbol \\omega'(\\vec r) =  \\mathbf p^T \\boldsymbol \\omega(\\vec r) = \\rho$. The anser is the following\n",
    "$$\n",
    "\\boldsymbol \\omega' = \\big(A^{-1}\\big)^T \\boldsymbol \\omega \\ \\text{ , since then: } \\ \\rho' =  \\mathbf p'^T \\boldsymbol \\omega' = (A \\mathbf p)^T  \\big(A^{-1}\\big)^T \\boldsymbol \\omega = \\mathbf p^T \\big(A^{-1} A\\big)^T \\boldsymbol \\omega = \\rho .\n",
    "$$\n",
    "\n",
    "In components, this transformation behavior reads $\\omega'_\\mu = \\big[ \\big(A^{-1}\\big)^T\\big]_{\\mu \\nu} \\omega_\\nu = \\omega_\\nu \\big(A^{-1}\\big)_{\\nu \\mu}$\n",
    "Thus, when interpreting $\\boldsymbol \\omega$ as row vector, it transforms like $\\boldsymbol \\omega'^T = \\boldsymbol \\omega^T A^{-1}$, that is, $\\boldsymbol \\omega$ transforms as dual vector (with the inverse of $A$ from the right), as can be seen in the `transform_tensor` function in [basis_transforms.py](../../mldft/ml/data/components/basis_transforms.py).  \n",
    "\n",
    "\n",
    "Lastly, we want to answer the following question: How can we look at the transformed basis functions $\\boldsymbol \\omega'$ without actually chaning the basis function but by changing the coefficients? For that, we consider the special \"density\" defined by\n",
    "$$\n",
    "\\omega'_\\sigma(\\vec r) = \\big (p^{(\\sigma)} \\big )^T \\boldsymbol \\omega'(\\vec r) , \\ \\text{ with }  \\ p^{(\\sigma)}_\\mu = \\begin{cases} 1 \\ \\text{ if }  \\ \\mu = \\sigma \\\\\n",
    "0  \\ \\text{ else } \\end{cases} .\n",
    "$$\n",
    "Now, based on the above considerations, we know how find the appropriate coefficients to visualize this density in the original untransformed basis, namely:\n",
    "$$\n",
    "\\omega'_\\sigma(\\vec r) = \\big ( \\mathbf p^{(\\sigma)} \\big )^T \\boldsymbol \\omega'(\\vec r) = \\big (\\mathbf p^{(\\sigma)} \\big )^T \\Big( \\big(A^{-1}\\big)^T \\boldsymbol \\omega \\Big) = \\big (A^{-1}   \\mathbf p^{(\\sigma)} \\big )^T \\boldsymbol \\omega\n",
    "$$\n",
    "So, we conclude that we can effectively visualize the transformed basis function $\\omega'_\\sigma(\\vec r)$ in untransformed basis by using the following coefficients:\n",
    "$$\n",
    "\\mathbf p'^{(\\sigma)} = A^{-1} \\mathbf p^{(\\sigma)} .\n",
    "$$ \n",
    "This is exactly what we will do below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3298f06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we apply a transform to the coeffs to see how the basis function changes:\n",
    "from mldft.ml.data.components.basis_transforms import transform_tensor\n",
    "from mldft.ml.data.components.of_data import Representation\n",
    "\n",
    "# actually we transform the coeffs with the inverse to see how the basis function will change:\n",
    "# (see explanation above)\n",
    "transformed_coeffs = transform_tensor(\n",
    "    tensor=torch.from_numpy(coeffs).float(),\n",
    "    transformation_matrix=transformation_matrix.T,  # the transpose is the inverse for Wigner-D matrices\n",
    "    inv_transformation_matrix=transformation_matrix,  # the inverse of the inverse is the original matrix\n",
    "    representation=Representation.VECTOR,  # ensures multiplication with A^{-1} from the left (see above)\n",
    ")\n",
    "\n",
    "# this can be used to visualize local frames\n",
    "global_frame_mesh = get_local_frames_mesh_dict(\n",
    "    origins=sample.pos[node_idx].view(1, 3),  # at the position of the atom\n",
    "    bases=lframes[node_idx].view(1, 3, 3),  # use local frame instead of global frame now\n",
    "    scale=2.5,\n",
    "    axes_radius_scale=0.06,\n",
    ")\n",
    "\n",
    "pl = pyvista.Plotter(off_screen=True, notebook=True, image_scale=1)\n",
    "pl = visualize_orbital(\n",
    "    mol=mol,\n",
    "    coeff=transformed_coeffs,\n",
    "    plotter=pl,\n",
    "    mode=\"isosurface\",\n",
    "    resolution=0.15,\n",
    "    isosurface_quantile=0.6,\n",
    "    bond_radius=0.1,\n",
    ")\n",
    "\n",
    "pl.add_mesh(**global_frame_mesh)\n",
    "print(\"P-Orbital like basis function after local frames transformation (and local frame):\")\n",
    "img = pl.show(screenshot=True, window_size=(800, 400))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "632e994a",
   "metadata": {},
   "source": [
    "For more information, on irreducible representations, equivariance with respect to rotations and the Wigner-D matrices consider watching the following lecture video [part 1](https://www.youtube.com/watch?v=gbEaHqJA9vI) and [part 2](https://www.youtube.com/watch?v=1-Z50VmIf9s)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97162a3e",
   "metadata": {},
   "source": [
    "Indeed, we can see that the basis function is transformed. First the blue part of the handles points in the direction of the red axis of the **global** reference frame (first visulalization), and after the transform the blue part of the handles points in the direction of the red axis of the **local** reference frame."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dbc4b06",
   "metadata": {},
   "source": [
    "## 3 Visualization of NatRep transformation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa44136d",
   "metadata": {},
   "source": [
    "As a next step, let us visualize the effect of global symmetric natrep\n",
    "together with the local frames transform on the same basis function that we visualized above.\n",
    "\n",
    "\n",
    "The effect of global symmetric natrep is that the basis function is now a linear combination of all basis functions where the coefficients of that linear combination are obtained from the basis change that diagonalizes the overlap matrix. \n",
    "\n",
    "\n",
    "Therefore the basis function will be more delocalized but in particular the *symmetric* version of global natrep ensures that the overlap of the old and the new basis functions is maximized under the following metric:\n",
    "$$\n",
    "\\left \\| u - v \\right \\|^2 = \\int \\vert u(\\vec r) - v(\\vec r) \\vert^2 \\mathrm \\ \\mathrm d^3\\vec r \n",
    "$$\n",
    "Thus, the old and the new basis function are still fairly similar.\n",
    "In doing so, the *symmetric* natrep ensures that the new basis functions are still fairly localized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30089d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the following will ensure that the basis transforms transformation matrix is added to the sample:\n",
    "datamodule_no_cache.transforms.add_transformation_matrix = True\n",
    "sample_with_trafo = datamodule_no_cache.train_set[0]\n",
    "\n",
    "# now we apply a transform to the coeffs to see how the basis function changes:\n",
    "\n",
    "# actually we transform the coeffs with the inverse to see how the basis function will change:\n",
    "# (see explanation above)\n",
    "transformed_coeffs2 = transform_tensor(\n",
    "    tensor=torch.from_numpy(coeffs).float(),\n",
    "    transformation_matrix=sample_with_trafo.inv_transformation_matrix,  # use the inverse transformation matrix\n",
    "    inv_transformation_matrix=sample_with_trafo.transformation_matrix,  # the inverse of the inverse is the original matrix\n",
    "    representation=Representation.VECTOR,  # ensures multiplication with A^{-1} from the left (see above)\n",
    ")\n",
    "\n",
    "# this can be used to visualize local frames\n",
    "# (in this case just the global coordinate frame at the origin)\n",
    "global_frame_mesh = get_local_frames_mesh_dict(\n",
    "    origins=sample.pos[node_idx].view(1, 3),\n",
    "    bases=lframes[node_idx].view(1, 3, 3),  # use local frame instead of global frame now\n",
    "    scale=2.5,\n",
    "    axes_radius_scale=0.06,\n",
    ")\n",
    "\n",
    "isosurface_quantile = 0.9\n",
    "pl = pyvista.Plotter(off_screen=True, notebook=True, image_scale=1)\n",
    "pl = visualize_orbital(\n",
    "    mol=mol,\n",
    "    coeff=transformed_coeffs2,\n",
    "    plotter=pl,\n",
    "    mode=\"isosurface\",\n",
    "    resolution=0.15,\n",
    "    isosurface_quantile=isosurface_quantile,\n",
    "    bond_radius=0.1,\n",
    ")\n",
    "\n",
    "pl.add_mesh(**global_frame_mesh)\n",
    "\n",
    "print(\n",
    "    \"P-Orbital like basis function after local frames transformation and global symmetric natrep (and local frame):\"\n",
    ")\n",
    "print(\n",
    "    f\"Visualized with isosurface_quantile={isosurface_quantile} (play around to see different iso surfaces).\"\n",
    ")\n",
    "img = pl.show(screenshot=True, window_size=(800, 400))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mldft",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
